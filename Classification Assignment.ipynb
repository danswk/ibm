{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56839f73-bd31-4492-ac0b-12d808c30e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'http://kaggle.com/datasets/kumarajarshi/life-expectancy-who'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9cab6-04de-4cda-9666-12771bf28b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:"
     ]
    }
   ],
   "source": [
    "data_dir = './life-expectancy-who'\n",
    "\n",
    "!sudo apt-get install texlive-xetex\n",
    "!jupyter nbconvert --to pdf 'Classification Assignment.ipynb'\n",
    "\n",
    "import os\n",
    "os.listdir(data_dir)\n",
    "!pip install skillsnetwork[regular]\n",
    "\n",
    "!pip install opendatasets --upgrade\n",
    "import opendatasets as od\n",
    "od.download(dataset)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import accumulate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077409d-ba07-4b6a-8b49-e795832bc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Life Expectancy Data.csv')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737e3bb-0112-4c30-b4fb-752300606e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={data.columns[3]: 'Life expectancy',\n",
    "                     data.columns[4]: 'Adult mortality',\n",
    "                     data.columns[5]: 'Infant deaths',\n",
    "                     data.columns[7]: 'Health expenditure',\n",
    "                     data.columns[9]: 'Measles',\n",
    "                     data.columns[10]: 'BMI',\n",
    "                     data.columns[11]: 'Under-5 deaths',\n",
    "                     data.columns[14]: 'Diphtheria',\n",
    "                     data.columns[15]: 'HIV/AIDS',\n",
    "                     data.columns[18]: 'Thinness (1-19 years)',\n",
    "                     data.columns[19]: 'Thinness (5-9 years)'},\n",
    "                    inplace=True)\n",
    "\n",
    "null_count = data.isnull().sum()\n",
    "print(null_count[null_count>0].sort_values(ascending=False),\n",
    "      'Number of null entries:', null_count.sum())\n",
    "\n",
    "for column in data:\n",
    "    if data[column].isnull().sum() > 0:\n",
    "        median = data[column].median()\n",
    "        data[column].fillna(median, inplace=True)\n",
    "null_count = data.isnull().sum()\n",
    "print('Number of null entries after replacement:', null_count.sum())\n",
    "\n",
    "print('Number of duplicated rows:', data.duplicated().sum())\n",
    "\n",
    "# Country column is categorical but not worth encoding - far too many classes and not useful for classification\n",
    "data = data.drop('Country', axis=1)\n",
    "\n",
    "# Shift target variable column to last position\n",
    "first = data.pop('Status')\n",
    "data.insert(len(data.columns), 'Status', first)\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35dad7-8f09-4a60-a8fe-f68f53d79ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "x_cols = data.columns[:-1]\n",
    "x_data = data[x_cols]\n",
    "y_col = 'Status'\n",
    "y_data = data[y_col]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, \n",
    "                                                    test_size=0.25, random_state=42)\n",
    "\n",
    "print('Number of train samples:', x_train.shape[0])\n",
    "print('Number of test samples:', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e3d4e-bbc8-4976-960f-bc262f316467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_test_poly = poly.transform(x_test)\n",
    "x_poly = poly.transform(x_data)\n",
    "\n",
    "print(x_train_poly.shape)\n",
    "print(x_test_poly.shape)\n",
    "# 20 original features + 210 polynomial features = 230 total features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb6703-d791-47c5-9675-8b1177ea6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_train_s = pd.DataFrame(x_train, columns=x_data.columns)\n",
    "x_test = ss.transform(x_test)\n",
    "x_test_s = pd.DataFrame(x_test, columns=x_data.columns)\n",
    "\n",
    "x_train_s.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c0950-792d-4529-9ab0-c2debc7c422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression - high interpretability\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_s, y_train)\n",
    "y_pred_lr = lr.predict(x_test_s)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Developing', 'Developed'], \n",
    "            yticklabels=['Developing', 'Developed'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()\n",
    "# Better performance for 'Developing' class but good overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1aae5-fe6a-41a4-9779-b957d2788bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 regularized logistic regression - high interpretability\n",
    "lr_l1 = LogisticRegressionCV(Cs=10, cv=4, penalty='l1', solver='liblinear')\n",
    "lr_l1.fit(x_train_s, y_train)\n",
    "y_pred_lr_l1 = lr_l1.predict(x_test_s)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr_l1)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Developing', 'Developed'], \n",
    "            yticklabels=['Developing', 'Developed'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.title('Confusion Matrix (L1 Logistic Regression)')\n",
    "\n",
    "plt.show()\n",
    "# No notable improvement in performance over non-regularised logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db8253-8a76-4ade-bc5b-6da9ba885389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularized logistic regression - high interpretability\n",
    "lr_l2 = LogisticRegressionCV(Cs=10, cv=4, penalty='l2', solver='liblinear')\n",
    "lr_l2.fit(x_train_s, y_train)\n",
    "y_pred_lr_l2 = lr_l2.predict(x_test_s)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr_l2)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Developing', 'Developed'], \n",
    "            yticklabels=['Developing', 'Developed'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.title('Confusion Matrix (L2 Logistic Regression)')\n",
    "\n",
    "plt.show()\n",
    "# Improvement over L1 regularisation for 'Developed' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576bb0ac-1af0-4fbd-b597-b00d388ad313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "coef = lr.coef_\n",
    "coef_df = pd.DataFrame({'Feature': x_train_s.columns, 'Coefficient': coef[0]}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "display(coef_df)\n",
    "# Thinness (in young people up to 19 years) has strongest positive correlation with positive class ('Developing') of target\n",
    "# variable ('Status')\n",
    "# Checks out as developing countries are more likely to suffer from food scarcity\n",
    "# Human Development Index in terms of income composition of resources has strongest negative correlation\n",
    "# Checks out as both variables track the same characteristic but 'Status' variable is the categorical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d9c55-d9ca-44f1-b1f5-9994ff16a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbors - low interpretability, moderate predictability\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neighbors = [1, 2, 3, 4]\n",
    "errors = []\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "for i, neighbor in enumerate(neighbors):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    knc = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    knc.fit(x_train, y_train)\n",
    "    y_pred_knc = knc.predict(x_test)   \n",
    "    cm_knc = confusion_matrix(y_test, y_pred_knc)\n",
    "    sns.heatmap(cm_knc, annot=True, fmt='d', cmap='Blues', ax=ax[row, col], \n",
    "                xticklabels=['Developing', 'Developed'], \n",
    "                yticklabels=['Developing', 'Developed'])\n",
    "    ax[row, col].set_title(f'Confusion Matrix ({neighbor} Nearest Neighbours)')\n",
    "    ax[row, col].set_xlabel('Predictions')\n",
    "    ax[row, col].set_ylabel('Ground Truth')\n",
    "\n",
    "plt.show()\n",
    "# All very similar\n",
    "# 'Developing' class predicted best when considering 2 nearest neighbours\n",
    "# 'Developed' class predicted best when considering only single nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb065f28-803e-4bff-9e8a-e0d74ddd7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest - high predictability\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred_rfc = rfc.predict(x_test)\n",
    "cm_rfc = confusion_matrix(y_test, y_pred_rfc)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_rfc, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Developing', 'Developed'], \n",
    "            yticklabels=['Developing', 'Developed'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.title('Confusion Matrix (Random Forest)')\n",
    "\n",
    "plt.show()\n",
    "# Notable improvement over logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80b6dc-4ab6-4267-b027-c1380eb8ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra trees - high predictability\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier()\n",
    "etc.fit(x_train, y_train)\n",
    "y_pred_etc = etc.predict(x_test)\n",
    "cm_etc = confusion_matrix(y_test, y_pred_etc)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_etc, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Developing', 'Developed'], \n",
    "            yticklabels=['Developing', 'Developed'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.title('Confusion Matrix (Extra Trees)')\n",
    "\n",
    "plt.show()\n",
    "# Improvement over random forest - best result of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354360d-6192-45d3-b2b0-9fcb4abc5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rfc.feature_importances_\n",
    "fi_df = pd.DataFrame({'Feature': x_train_s.columns, 'Importance': fi}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "display(fi_df)\n",
    "# Alcohol (consumption per capita in litres) has greatest effect on predictions\n",
    "# Quite unexpected as did not personally associate alcohol consumption with development status of a country\n",
    "# HIV/AIDS (deaths per 1,000 live births (0-4 years)) has least effect on predictions\n",
    "# Implies that deaths from HIV/AIDS are not more common in developing countries compared to developed countries or vice-versa\n",
    "# to any significant degree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
