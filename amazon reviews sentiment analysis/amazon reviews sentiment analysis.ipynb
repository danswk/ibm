{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9cbc854-162e-4ce5-9083-8ca1df070726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.ft.txt.bz2', 'train.ft.txt.bz2', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf.keras.optimizers import Adam\n",
    "from tf.keras.models import Model, Sequential\n",
    "from tf.keras.preprocessing.text import Tokenizer\n",
    "from tf.keras.layers import Conv1D, Dense, Dropout, Embedding, Flatten, Input, MaxPooling1D\n",
    "\n",
    "import re\n",
    "import bz2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "data_dir = './amazon'\n",
    "print(os.listdir(data_dir))  # files present in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cfaaed-4df6-4392-8dd2-9ab1996d9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_texts(file):\n",
    "    labels = []\n",
    "    texts = []\n",
    "    for line in bz2.BZ2File(file):\n",
    "        d = line.decode('utf-8')  # decode 8-bit encodings of source text to ascii\n",
    "        labels.append(int(d[9]) - 1)  # extract labels, shifts index [1,2] to [0,1]\n",
    "        texts.append(d[10:])  # append review content\n",
    "    return np.array(labels), texts\n",
    "\n",
    "train_labels, train_texts = get_labels_and_texts('./amazon/train.ft.txt.bz2')\n",
    "test_labels, test_texts = get_labels_and_texts('./amazon/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f57435-24fb-454f-81e5-af8e9e9ee229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_texts(texts):\n",
    "    normalized_texts = []\n",
    "    for text in texts:\n",
    "        no_cap = text.lower()  # change uppercase to lowercase\n",
    "        no_pun = re.sub(r'[^\\w\\s]', '', no_cap)  # remove punctuation\n",
    "        no_non = re.sub(r'[^\\x00-\\x7F]', '', no_pun)  # remove non-ascii\n",
    "        no_spa = no_non.strip()  # remove leading/trailing spaces\n",
    "        normalized_texts.append(no_spa)\n",
    "    return normalized_texts\n",
    "        \n",
    "train_texts = normalize_texts(train_texts)\n",
    "test_texts = normalize_texts(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea5d815c-23cc-4e2a-843f-13b1b123c27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuning even for the nongamer this sound track was beautiful it paints the senery in your mind so well i would recomend it even to people who hate vid game music i have played the game chrono cross but out of all of the games i have ever played it has the best music it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras it would impress anyone who cares to listen _',\n",
       " 'the best soundtrack ever to anything im reading a lot of reviews saying that this is the best game soundtrack and i figured that id write a review to disagree a bit this in my opinino is yasunori mitsudas ultimate masterpiece the music is timeless and im been listening to it for years now and its beauty simply refuses to fadethe price tag on this is pretty staggering i must say but if you are going to buy any cd for this much money this is the only one that i feel would be worth every penny',\n",
       " 'amazing this soundtrack is my favorite music of all time hands down the intense sadness of prisoners of fate which means all the more if youve played the game and the hope in a distant promise and girl who stole the star have been an important inspiration to me personally throughout my teen years the higher energy tracks like chrono cross  times scar time of the dreamwatch and chronomantique indefinably remeniscent of chrono trigger are all absolutely superb as wellthis soundtrack is amazing music probably the best of this composers work i havent heard the xenogears soundtrack so i cant say for sure and even if youve never played the game it would be worth twice the price to buy iti wish i could give it 6 stars',\n",
       " 'excellent soundtrack i truly like this soundtrack and i enjoy video game music i have played this game and most of the music on here i enjoy and its truly relaxing and peacefulon disk one my favorites are scars of time between life and death forest of illusion fortress of ancient dragons lost fragment and drowned valleydisk two the draggons galdorb  home chronomantique prisoners of fate gale and my girlfriend likes zelbessdisk three the best of the three garden of god chronopolis fates jellyfish sea burning orphange dragons prayer tower of stars dragon god and radical dreamers  unstealable jeweloverall this is a excellent soundtrack and should be brought by those that like video game musicxander cross']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[:4]  # texts successfully normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9becef1-3939-41da-87f8-febde47adbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ac4ea-9cbf-4c82-a111-d50541bea20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "# train_pickle = pickle.dumps(train_sequences)\n",
    "# with open('train_pickle.pkl', 'wb') as file:\n",
    "#     file.write(train_pickle)\n",
    "\n",
    "# test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "# test_pickle = pickle.dumps(test_sequences)\n",
    "# with open('test_pickle.pkl', 'wb') as file:\n",
    "#     file.write(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb3c813-b404-4c3a-8d8b-c4f3203abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_pickle.pkl', 'rb') as file:\n",
    "    train_pickle = file.read()\n",
    "train_sequences = pickle.loads(train_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da21bec-6203-45cf-a9a8-42262fd93424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "      <td>495</td>\n",
       "      <td>13</td>\n",
       "      <td>363</td>\n",
       "      <td>7</td>\n",
       "      <td>6002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1001</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>247</td>\n",
       "      <td>106</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>347</td>\n",
       "      <td>8</td>\n",
       "      <td>1001</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>297</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>470</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>278</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2    3    4    5     6    7    8     9    ...  108   109  \\\n",
       "0   72    11     1    8  173  495    13  363    7  6002  ...  NaN   NaN   \n",
       "1    1    87  1001  131    5  247   106  147    4   170  ...  NaN   NaN   \n",
       "2  347     8  1001    9   21  297   119    6   27    55  ...  5.0  82.0   \n",
       "3  180  1001     3  470   32    8  1001    2    3   278  ...  NaN   NaN   \n",
       "\n",
       "      110    111  112   113    114  115    116    117  \n",
       "0     NaN    NaN  NaN   NaN    NaN  NaN    NaN    NaN  \n",
       "1     NaN    NaN  NaN   NaN    NaN  NaN    NaN    NaN  \n",
       "2  2194.0  332.0  3.0  99.0  174.0  7.0  489.0  259.0  \n",
       "3     NaN    NaN  NaN   NaN    NaN  NaN    NaN    NaN  \n",
       "\n",
       "[4 rows x 118 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_sequences[:4])  # texts successfully tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c685137d-5cf7-4ee5-92b9-a1216660c40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326947\n",
      "254\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "\n",
    "max_features = 10000\n",
    "embedding_dim = 100\n",
    "\n",
    "max_length = max(len(sequence) for sequence in train_sequences)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90dfda21-35ab-4500-967d-6337fcec2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    sequences = layers.Input(shape=(max_length,))\n",
    "    embedding = layers.Embedding(input_dim=max_features, output_dim=embedding_dim)(sequences)\n",
    "    \n",
    "    x = layers.Conv1D(64, 5, activation='relu')(embedding)  # capture higher-level patterns\n",
    "    x = layers.MaxPool1D(5)(x)  # reduce dimensionality\n",
    "    x = layers.Conv1D(64, 3, activation='relu')(x)  # capture more fine-grained patterns\n",
    "    x = layers.MaxPool1D(3)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dropout(.5)(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.Dropout(.5)(x)\n",
    "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs=sequences, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5056ed-7446-4e59-b142-fbdc697f7cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 20:47:16.328292: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 254)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 254, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 250, 64)           32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 48, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,077,761\n",
      "Trainable params: 1,077,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aabffd3e-aaec-4e1c-a7fe-ad062dbd8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_pickle.pkl', 'rb') as file:\n",
    "    test_pickle = file.read()\n",
    "test_sequences = pickle.loads(test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2da08e-284d-4b9b-bccd-7a5682989047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested different methods of preparing data for model fitting\n",
    "# convert_to_tensor: only takes sequences of same length but data not padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de90e4e-3a7c-4f7a-a284-6713afc73ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_length)\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ba6843-dead-4ca7-86e5-5a94a675fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 13:07:49.035141: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "28125/28125 [==============================] - 2604s 92ms/step - loss: 0.1896 - accuracy: 0.9336 - val_loss: 0.1495 - val_accuracy: 0.9452\n",
      "Epoch 2/2\n",
      "28125/28125 [==============================] - 2473s 88ms/step - loss: 0.1588 - accuracy: 0.9466 - val_loss: 0.1440 - val_accuracy: 0.9488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd853401c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_sequences, train_labels,\n",
    "    batch_size=128, epochs=2, verbose=1,\n",
    "    validation_data=(test_sequences, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a2aa4-ef89-4916-a7fb-7c1d536df837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested different methods of scoring model performance\n",
    "# classification_report: only takes binary values but test_labels_pred values are float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58bb358b-0446-430b-87ea-db76842e12b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9488\n",
      "F1 score: 0.9486\n",
      "ROC-AUC score: 0.9877\n"
     ]
    }
   ],
   "source": [
    "test_labels_pred = model.predict(test_sequences)\n",
    "print(f'Accuracy score: {np.round(accuracy_score(test_labels, 1 * (test_labels_pred > 0.5)), 4)}')\n",
    "print(f'F1 score: {np.round(f1_score(test_labels, 1 * (test_labels_pred > 0.5)),4)}')\n",
    "print(f'ROC-AUC score: {np.round(roc_auc_score(test_labels, test_labels_pred),4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
